{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression — Brezina ch. 4 + Google's Crash Course in Machine Learning\n",
    "\n",
    "Because Brezina's explanations are sparse (no pun intended), we're going to lean on Google's Crash Course in Machine Learning to talk about Logistic Regression.\n",
    "\n",
    "But first, we'll need to look at [linear regression](https://developers.google.com/machine-learning/crash-course/linear-regression).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Linear Regression\n",
    "\n",
    "https://developers.google.com/machine-learning/crash-course/linear-regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add as many cells as you need\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linear regression is a statistical technique used to find the relationship between variables. \n",
    "In an ML context, linear regression finds the relationship between features and a label."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "y` = b + w1x1\n",
    "where:\n",
    "\n",
    " y` is the predicted label—the output.\n",
    "\n",
    " b is the bias of the model. Bias is the same concept as the y-intercept in the algebraic equation for a line. In ML, bias is sometimes referred to as w0. Bias is a parameter of the model and is calculated during training.\n",
    "\n",
    " w1 is the weight of the feature. Weight is the same concept as the slope  in the algebraic equation for a line. Weight is a parameter of the model and is calculated during training.\n",
    "\n",
    " x1 is a feature—the input.\n",
    "\n",
    " more features means adding w2x2, w3x3..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "During training, the model updates the bias and weights based on loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loss: numerical metric that describes how wrong a model's predictions are. Loss measures the distance between the model's predictions and the actual labels. The goal of training a model is to minimize the loss, reducing it to its lowest possible value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualizing loss: arrows drawn between points and the line of regression\n",
    "In statistics and machine learning, loss measures the difference between the predicted and actual values. Focus is on distance, not direction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Four main types of loss: \n",
    "L1 loss: the sume of the absolute values of the difference between the predicted values and the actual values\n",
    "\n",
    "Mean absolute error (MAE): the average L1 losses across a set of examples\n",
    "\n",
    "L2 Loss: the sum of the squared difference between the predicted values and the actual values\n",
    "\n",
    "Mean squared error (MSE): the average of L2 losses across a set of examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MSE vs MAE\n",
    "\n",
    "The functional difference between L1 loss and L2 loss (or between MAE and MSE) is squaring. When the difference between the prediction and label is large, squaring makes the loss even larger. When the difference is small (less than 1), squaring makes the loss even smaller.\n",
    "\n",
    "When processing multiple examples at once, we recommend averaging the losses across all the examples, whether using MAE or MSE.\n",
    "\n",
    "When choosing the best loss function, consider how you want the model to treat outliers. For instance, MSE moves the model more toward the outliers, while MAE doesn't. L2 loss incurs a much higher penalty for an outlier than L1\n",
    "\n",
    "MSE: The model is closer to the outliers but further away from most of the other data points.\n",
    "\n",
    "MAE: The model is further away from the outliers but closer to most of the other data points.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gradient Descent: Gradient descent is a mathematical technique that iteratively finds the weights and bias that produce the model with the lowest loss. Gradient descent finds the best weight and bias by repeating the following process for a number of user-defined iterations.\n",
    "\n",
    "\n",
    "Training model steps\n",
    "Step 1: set weight and bias to 0\n",
    "Step 2: draw loss lines and use MSE\n",
    "Step 3: Calculate the loss with the current weight and bias.\n",
    "Step 4: Determine the direction to move the weights and bias that reduce loss.\n",
    "Step 5: Move the weight and bias values a small amount in the direction that reduces loss.\n",
    "\n",
    "Return to step 3 and repeat the process until the model can't reduce the loss any further.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hyperparameters: variables that control different aspects of training\n",
    "Three common types:\n",
    "    Learning rate\n",
    "    Batch size\n",
    "    Epochs\n",
    "\n",
    "Parameters: variables that are part of the model itself.\n",
    "\n",
    "In other words, hyperparameters are values that you control; parameters are values that the model calculates during training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Learning rate\n",
    "\n",
    "Learning rate is a floating point number you set that influences how quickly the model converges. If the learning rate is too low, the model can take a long time to converge. However, if the learning rate is too high, the model never converges, but instead bounces around the weights and bias that minimize the loss. The goal is to pick a learning rate that's not too high nor too low so that the model converges quickly.\n",
    "\n",
    "The learning rate determines the magnitude of the changes to make to the weights and bias during each step of the gradient descent process. The model multiplies the gradient by the learning rate to determine the model's parameters (weight and bias values) for the next iteration. In the third step of gradient descent, the \"small amount\" to move in the direction of negative slope refers to the learning rate.\n",
    "\n",
    "The difference between the old model parameters and the new model parameters is proportional to the slope of the loss function. For example, if the slope is large, the model takes a large step. If small, it takes a small step. For example, if the gradient's magnitude is 2.5 and the learning rate is 0.01, then the model will change the parameter by 0.025.\n",
    "\n",
    "The ideal learning rate helps the model to converge within a reasonable number of iterations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Batch size\n",
    "\n",
    "Batch size is a hyperparameter that refers to the number of examples the model processes before updating its weights and bias. You might think that the model should calculate the loss for every example in the dataset before updating the weights and bias. However, when a dataset contains hundreds of thousands or even millions of examples, using the full batch isn't practical.\n",
    "\n",
    "Two common techniques to get the right gradient on average without needing to look at every example in the dataset before updating the weights and bias are stochastic gradient descent and mini-batch stochastic gradient descent:\n",
    "\n",
    "Stochastic gradient descent (SGD): Stochastic gradient descent uses only a single example (a batch size of one) per iteration. Given enough iterations, SGD works but is very noisy. \"Noise\" refers to variations during training that cause the loss to increase rather than decrease during an iteration. The term \"stochastic\" indicates that the one example comprising each batch is chosen at random.\n",
    "\n",
    "Mini-batch stochastic gradient descent (mini-batch SGD): Mini-batch stochastic gradient descent is a compromise between full-batch and SGD. For N number of data points, the batch size can be any number greater than 1 and less than N . The model chooses the examples included in each batch at random, averages their gradients, and then updates the weights and bias once per iteration.\n",
    "\n",
    "Determining the number of examples for each batch depends on the dataset and the available compute resources. In general, small batch sizes behaves like SGD, and larger batch sizes behaves like full-batch gradient descent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Epochs\n",
    "\n",
    "During training, an epoch means that the model has processed every example in the training set once. For example, given a training set with 1,000 examples and a mini-batch size of 100 examples, it will take the model 10 iterations to complete one epoch.\n",
    "\n",
    "Training typically requires many epochs. That is, the system needs to process every example in the training set multiple times.\n",
    "\n",
    "The number of epochs is a hyperparameter you set before the model begins training. In many cases, you'll need to experiment with how many epochs it takes for the model to converge. In general, more epochs produces a better model, but also takes more time to train."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Batch type: When weights and bias updates occur\n",
    "\n",
    "\n",
    "Full batch:\tAfter the model looks at all the examples in the dataset. For instance, if a dataset contains 1,000 examples and the model trains for 20 epochs, the model updates the weights and bias 20 times, once per epoch.\n",
    "\n",
    "Stochastic gradient descent:\tAfter the model looks at a single example from the dataset. For instance, if a dataset contains 1,000 examples and trains for 20 epochs, the model updates the weights and bias 20,000 times.\n",
    "\n",
    "Mini-batch stochastic gradient descent:\tAfter the model looks at the examples in each batch. For instance, if a dataset contains 1,000 examples, and the batch size is 100, and the model trains for 20 epochs, the model updates the weights and bias 200 times."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Doubling the learning rate can result in a learning rate that is too large, and therefore cause the weights to \"bounce around,\" increasing the amount of time needed to converge. As always, the best hyperparameters depend on your dataset and available compute resources.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Learning rate controls the size of the steps of the gradient descent algorithm\n",
    "\n",
    "Suppose you are training a linear regression model and after about 100 iterations you notice that the loss is high and trending downward, but not by a significant amount. What is likely to be the problem? Answer: learning rate is too small\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression\n",
    "\n",
    "https://developers.google.com/machine-learning/crash-course/logistic-regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# again, add code cells and experiment as needed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic regression: a type of regression model that predicts a probability\n",
    "\n",
    "\n",
    "Need to transform model to output continuous values. Create sigmoid curve, used to map outputs.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "z = b + w1x1 + w2x2 +w3x3... + wNxN\n",
    "\n",
    "y` = 1/ (1+e^-z)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#example of equation\n",
    "\n",
    "1+(2*0)+(-1*10)+(5*2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7310585786300049\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "result = 1 / (1 + math.exp(-1))\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic regression models are trained using the same process as linear regression models, with two key distinctions:\n",
    "\n",
    "Logistic regression models use Log Loss as the loss function instead of squared loss.\n",
    "\n",
    "Applying regularization is critical to prevent overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Log Loss equation returns the logarithm of the magnitude of the change, rather than just the distance from data to prediction. Log Loss is calculated as follows:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regularization, a mechanism for penalizing model complexity during training, is extremely important in logistic regression modeling. Without regularization, the asymptotic nature of logistic regression would keep driving loss towards 0 in cases where the model has a large number of features. Consequently, most logistic regression models use one of the following two strategies to decrease model complexity:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why is linear regression model's output a porr predictor of probability?\n",
    "\n",
    "Answer: It's predictions are not restritcted to values between 0 and 1\n",
    "\n",
    "\n",
    "True or false: a Sigmoid function never outputs the value 0 or 1\n",
    "   \n",
    "Answer: True\n",
    "\n",
    "\n",
    "True or false: applying regularization is less important when training logistic regression models than it is for training linear regression models\n",
    " \n",
    "Answer: False\n",
    "\n",
    "\n",
    "Which of the following options matches both Linear Regression and Logistic Regression with appropriate loss functions for calculating loss?\n",
    "\n",
    "\n",
    "Answer: Linear Regression: mean squared error\n",
    "        Logistic regression: log loss\n",
    "\n",
    "\n",
    "Which of the following is an effective regularization technique for logistic regression models?\n",
    "\n",
    "Answer: Early stopping"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
